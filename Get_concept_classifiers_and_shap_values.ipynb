{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "from func.utils import get_model_output_id_wnid_class_dict # get mapping: format: {\"Model Ouput ID\": [\"WNID\", \"Class\"]}\n",
    "from func.utils import get_imagenet_id_wnid_class_dict # get mapping: format: {\"ImageNet ID\": [\"WNID\", \"class\"]}, e.g. {...\"233\": ['n02106382', 'Bouvier_des_Flandres'], ...}\n",
    "from func.utils import map_model_id_to_imagenet_id, map_imagenet_id_to_model_id # mapping funcs\n",
    "\n",
    "from func.utils import save_obj, load_obj\n",
    "\n",
    "from func.concept_classifier import get_linear_classifier, get_xgb_classifier, prediction, batch\n",
    "\n",
    "from func.responsible_regions import load_responsible_regions_from_given_path, X_y_preparation, process_cat_saliency_map\n",
    "\n",
    "from func.show import load_feature_saliency_map_and_resized_img_for_show, show_concept_region_on_img\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import gc\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dict of ImageNet ID, WNID and class name\n",
    "# format: {\"ImageNet ID\": [\"WNID\", \"class\"]}, e.g. {...\"233\": ['n02106382', 'Bouvier_des_Flandres'], ...}\n",
    "imagenet_id_label=get_imagenet_id_wnid_class_dict(matfilepath = \"imagenet_info/ILSVRC2012_meta.mat\")\n",
    "\n",
    "# get the dict of model output ID, WNID and class name\n",
    "# format: {\"Model Ouput ID\": [\"WNID\", \"Class\"]}\n",
    "modeloutput_id_label=get_model_output_id_wnid_class_dict(jsonfilepath = \"imagenet_info/imagenet_label_index.json\")\n",
    "\n",
    "# get dict map model output ID to ImageNet ID\n",
    "map_dict_model2imagenet=map_model_id_to_imagenet_id(imagenet_id_label, modeloutput_id_label)\n",
    "\n",
    "# get ImageNet ID to dict map model output ID\n",
    "map_dict_imagenet2model=map_imagenet_id_to_model_id(imagenet_id_label, modeloutput_id_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show imagenet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only 1~1000 is valid\n",
    "for idx in imagenet_id_label:\n",
    "    print(str(idx)+\": \"+str(imagenet_id_label[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imagenet parent and child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_class_parent_and_child_dict = load_obj(\"imagenet_info/imagenet_class_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "imagenet_class_parent_and_child_dict[1095]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept classifier and Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to responsible regions\n",
    "responisble_regions_save_path = \"output/responsible_regions_vgg19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under that path, there are responsible regions of diff layers...\n",
    "print(os.listdir(responisble_regions_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_layer = \"features.30\"\n",
    "print(\"chosen layer: \"+chosen_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are diff ID groups...\n",
    "print(os.listdir(os.path.join(responisble_regions_save_path, chosen_layer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ID_group = \"[1082, 1095, 1845]\"\n",
    "print(\"chosen_ID_group: \"+chosen_ID_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_y = np.load(os.path.join(responisble_regions_save_path, chosen_layer, chosen_ID_group, \"X_y.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the target obj (to the the concept classifier of the obj)\n",
    "target_obj_loc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = copy.deepcopy(X_y[\"y\"])\n",
    "print(\"target is \"+str(chosen_ID_group.split(\",\")[target_obj_loc]))\n",
    "print(imagenet_class_parent_and_child_dict[int(chosen_ID_group.split(\",\")[target_obj_loc])]['words'])\n",
    "print(\"we will train a concept classifier to distinguish the target from the others in \"+str(chosen_ID_group))\n",
    "y[y!=target_obj_loc] = -1\n",
    "y[y==target_obj_loc] = 1\n",
    "y[y!=1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the concept classifier\n",
    "coef, clf, Validation_score = get_linear_classifier(X_y[\"X\"], y, classifier = \"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_of_pos_input = clf.predict(X_y[\"X\"][y==1])\n",
    "pred_of_neg_input = clf.predict(X_y[\"X\"][y==0])\n",
    "\n",
    "precision = sum(pred_of_pos_input) / len(pred_of_pos_input)\n",
    "recall = sum(pred_of_pos_input) / (sum(pred_of_pos_input)+sum(pred_of_neg_input))\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(\"precision: \"+str(precision))\n",
    "print(\"recall: \"+str(recall))\n",
    "print(\"f1: \"+str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_save_the_clf = False\n",
    "\n",
    "clf_save_path = \"output/concept_clf\"\n",
    "if not os.path.exists(clf_save_path):\n",
    "    os.makedirs(clf_save_path)\n",
    "\n",
    "clf_name = \"concept_clf\"\n",
    "\n",
    "clf_dict = {}\n",
    "clf_dict[\"clf\"] = clf\n",
    "clf_dict[\"info\"] = {\"name\": \"classifier\", \"model\": \"vgg19\", \"layer\": chosen_layer}\n",
    "\n",
    "if need_to_save_the_clf:\n",
    "    save_obj(clf_dict, os.path.join(clf_save_path, clf_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train xgb_classifier and calculate Shapley Values with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = get_xgb_classifier(X_y[\"X\"],y)\n",
    "bst.set_param({\"predictor\": \"gpu_predictor\"})\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(X_y[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # if the size of X is too large...\n",
    "# # use the following code\n",
    "\n",
    "# X = copy.deepcopy(X_y[\"X\"])\n",
    "# ROUNDS = 5\n",
    "# K = 4\n",
    "# flag = True\n",
    "# for ROUND in range(ROUNDS):\n",
    "#     row_num = np.arange(X.shape[0])\n",
    "#     np.random.shuffle(row_num)\n",
    "#     X_shuffle = X[row_num, :]\n",
    "#     y_shuffle = y[row_num]\n",
    "#     batcherator = batch(X_shuffle, y_shuffle, int(X.shape[0] / K))\n",
    "#     for index, (chunk_X, chunk_y) in enumerate(batcherator):\n",
    "#         if len(chunk_X) == int(X.shape[0] / K):\n",
    "#             current_batch_size = len(chunk_X)\n",
    "#             print(\"batch size: \"+str(current_batch_size)+\" | \"+str(index)+\"th batch of \"+str(ROUND)+\"th round\", end=\"\\r\")\n",
    "#             if flag:\n",
    "#                 bst = get_xgb_classifier(chunk_X, chunk_y, model_para = False)\n",
    "#                 flag = False\n",
    "#             else:\n",
    "#                 bst = get_xgb_classifier(chunk_X, chunk_y, model_para = True)\n",
    "        \n",
    "# bst.set_param({\"predictor\": \"gpu_predictor\"})\n",
    "# explainer = shap.TreeExplainer(bst)\n",
    "        \n",
    "# batcherator_for_shap = batch(X, y, current_batch_size)\n",
    "# print(\"the batch size of shap cal is \"+str(current_batch_size))\n",
    "# for index, (chunk_X, chunk_y) in enumerate(batcherator_for_shap):\n",
    "#     if len(chunk_X) == current_batch_size:\n",
    "#         if index == 0:\n",
    "#             shap_values = explainer.shap_values(chunk_X)\n",
    "#             #dmat = xgb.DMatrix(data=chunk_X,label=chunk_y)\n",
    "#             #shap_values = bst.predict(dmat, pred_contribs=True)\n",
    "        \n",
    "#         else:\n",
    "#             shap_values = np.concatenate((shap_values, explainer.shap_values(chunk_X)))\n",
    "#             #dmat = xgb.DMatrix(data=chunk_X,label=chunk_y)\n",
    "#             #shap_values = np.concatenate((shap_values, bst.predict(dmat, pred_contribs=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_arr_mean = []\n",
    "importance_arr_median = []\n",
    "importance_arr_max = []\n",
    "importance_arr_min = []\n",
    "\n",
    "for i in range(shap_values.shape[1]):\n",
    "    shap_vals_of_one_channel = np.abs(shap_values[:,i]) #xgb_shap_values[:,i]\n",
    "    importance_arr_mean.append(np.mean(shap_vals_of_one_channel))\n",
    "    importance_arr_median.append(np.median(shap_vals_of_one_channel))\n",
    "    importance_arr_max.append(np.max(shap_vals_of_one_channel))\n",
    "    importance_arr_min.append(np.min(shap_vals_of_one_channel))\n",
    "\n",
    "importance_arr_mean = np.array(importance_arr_mean)\n",
    "importance_arr_median = np.array(importance_arr_median)\n",
    "importance_arr_max = np.array(importance_arr_max)\n",
    "importance_arr_min = np.array(importance_arr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shap vals\n",
    "\n",
    "sort_locs = np.argsort(importance_arr_mean)[::-1]\n",
    "\n",
    "sort_locs_str = []\n",
    "for i in sort_locs:\n",
    "     sort_locs_str.append(str(i))\n",
    "\n",
    "N_subplot = 7\n",
    "len_of_one_sub = int(len(sort_locs)/N_subplot+1)\n",
    "sort_locs_sub = []\n",
    "sort_locs_str_sub = []\n",
    "for i in range(N_subplot):\n",
    "    start_loc = np.clip(i*len_of_one_sub,0,len(sort_locs))\n",
    "    end_loc = np.clip((i+1)*len_of_one_sub,0,len(sort_locs))\n",
    "    sort_locs_sub.append(sort_locs[start_loc:end_loc])\n",
    "    sort_locs_str_sub.append(sort_locs_str[start_loc:end_loc])\n",
    "    \n",
    "fig, axs = plt.subplots(1,N_subplot,figsize=(20,20))\n",
    "\n",
    "for i in range(N_subplot):\n",
    "    axs[i].barh(sort_locs_str_sub[i][::-1],importance_arr_mean[sort_locs_sub[i]][::-1])\n",
    "    axs[i].set_xlim(0, np.max(importance_arr_mean)+0.05)\n",
    "    axs[i].set_xlabel('Shapley')\n",
    "# plt.savefig(\"shap_bar_plot.svg\",\n",
    "#             bbox_inches='tight', dpi=100, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save shap vals\n",
    "\n",
    "need_to_save_the_shap_vals = False\n",
    "shap_vals_save_path = \"output\"\n",
    "if need_to_save_the_shap_vals:\n",
    "    shap_df = pd.DataFrame(columns=['mean', 'median', 'max', 'min'])\n",
    "    shap_df['mean'] = importance_arr_mean\n",
    "    shap_df['median'] = importance_arr_median\n",
    "    shap_df['max'] = importance_arr_max\n",
    "    shap_df['min'] = importance_arr_min\n",
    "    shap_df.to_csv(os.path.join(shap_vals_save_path, \"shap_values.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the results of concept classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to load feature maps and saliency maps of a model\n",
    "feature_maps_and_saliency_maps_path = \"output/feature_maps_and_saliency_maps_vgg19\"\n",
    "\n",
    "ID_for_show = 1095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ID_for_show, imagenet_class_parent_and_child_dict[ID_for_show]['words'])\n",
    "\n",
    "resized_img_for_show_cat, feature_map_for_show_cat, saliency_map_for_show_cat = \\\n",
    "load_feature_saliency_map_and_resized_img_for_show(feature_maps_and_saliency_maps_path+\"/result_of_ID_\"+str(ID_for_show), chosen_layer)\n",
    "\n",
    "resized_img_for_show_cat = np.array(resized_img_for_show_cat, dtype=int)\n",
    "\n",
    "grayscale_saliency_map = process_cat_saliency_map(saliency_map_for_show_cat, num_of_pic_of_a_row = 10, mode=\"norm\")\n",
    "\n",
    "concept_map = prediction(clf, feature_map_for_show_cat, is_predict_proba = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_concept_region_on_img(resized_img_for_show_cat, concept_map[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
