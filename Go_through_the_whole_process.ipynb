{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "from func.utils import get_model_output_id_wnid_class_dict # get mapping: format: {\"Model Ouput ID\": [\"WNID\", \"Class\"]}\n",
    "from func.utils import get_imagenet_id_wnid_class_dict # get mapping: format: {\"ImageNet ID\": [\"WNID\", \"class\"]}, e.g. {...\"233\": ['n02106382', 'Bouvier_des_Flandres'], ...}\n",
    "from func.utils import map_model_id_to_imagenet_id, map_imagenet_id_to_model_id # mapping funcs\n",
    "\n",
    "from func.utils import save_obj, load_obj\n",
    "\n",
    "from func.saliency_maps import conduct_saliency_map_method, GuidedBackprop, VanillaBackprop, SmoothGrad, GradCAM, GuidedGradCAM, IntegratedGradients, GradientxInput\n",
    "\n",
    "from func.responsible_regions import load_responsible_regions_from_given_path, X_y_preparation, process_cat_saliency_map\n",
    "\n",
    "from func.concept_classifier import get_linear_classifier, get_xgb_classifier, prediction\n",
    "\n",
    "from func.show import load_feature_saliency_map_and_resized_img_for_show, show_concept_region_on_img\n",
    "\n",
    "# from func.receptive_field import receptive_field, get_rfs_from_a_mask, show_rf_in_org_img, show_some_rfs_randomly, show_some_rfs_order, get_rfs_from_a_mask_with_order\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dict of ImageNet ID, WNID and class name\n",
    "# format: {\"ImageNet ID\": [\"WNID\", \"class\"]}, e.g. {...\"233\": ['n02106382', 'Bouvier_des_Flandres'], ...}\n",
    "imagenet_id_label=get_imagenet_id_wnid_class_dict(matfilepath = \"imagenet_info/ILSVRC2012_meta.mat\")\n",
    "\n",
    "# get the dict of model output ID, WNID and class name\n",
    "# format: {\"Model Ouput ID\": [\"WNID\", \"Class\"]}\n",
    "modeloutput_id_label=get_model_output_id_wnid_class_dict(jsonfilepath = \"imagenet_info/imagenet_label_index.json\")\n",
    "\n",
    "# get dict map model output ID to ImageNet ID\n",
    "map_dict_model2imagenet=map_model_id_to_imagenet_id(imagenet_id_label, modeloutput_id_label)\n",
    "\n",
    "# get ImageNet ID to dict map model output ID\n",
    "map_dict_imagenet2model=map_imagenet_id_to_model_id(imagenet_id_label, modeloutput_id_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show imagenet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only 1~1000 is valid\n",
    "for idx in imagenet_id_label:\n",
    "    print(str(idx)+\": \"+str(imagenet_id_label[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imagenet parent and child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_class_parent_and_child_dict = load_obj(\"imagenet_info/imagenet_class_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g.\n",
    "imagenet_class_parent_and_child_dict[1095]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responisble regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to load feature maps and saliency maps of a model\n",
    "feature_maps_and_saliency_maps_path = \"output/feature_maps_and_saliency_maps_vgg19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ID_groups and layers\n",
    "ID_groups = [[1082,1095,1845]]\n",
    "layers = [\"features.30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to save responisble regions\n",
    "responisble_regions_save_path = \"output/responisble_regions\"\n",
    "\n",
    "if not os.path.exists(responisble_regions_save_path):\n",
    "    os.mkdir(responisble_regions_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs_str = []\n",
    "for ID_group in ID_groups:\n",
    "    IDs_str.append(str(ID_group))\n",
    "IDs_str = np.array(IDs_str)\n",
    "\n",
    "for ID_group in ID_groups:\n",
    "    for ID in ID_group:\n",
    "        print(ID, imagenet_class_parent_and_child_dict[ID]['words'], imagenet_class_parent_and_child_dict[ID]['gloss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx_layer, layer in enumerate(layers):\n",
    "    chosen_layer = layer\n",
    "    \n",
    "    save_layer_path = os.path.join(responisble_regions_save_path, chosen_layer)\n",
    "    if not os.path.exists(save_layer_path):\n",
    "        os.mkdir(save_layer_path)\n",
    "    \n",
    "    X_dict = {}\n",
    "    for ID_group in ID_groups:\n",
    "        for idx, ID in enumerate(ID_group):\n",
    "            print(\"loading data\", chosen_layer, ID, imagenet_class_parent_and_child_dict[ID]['words'], imagenet_class_parent_and_child_dict[ID]['gloss'])\n",
    "            if ID not in X_dict.keys():\n",
    "                X_pos_current, X_neg_current = load_responsible_regions_from_given_path(os.path.join(feature_maps_and_saliency_maps_path, \"result_of_ID_\"+str(ID)),\n",
    "                                                                                        layer = chosen_layer, pic_size = 14)\n",
    "                X_dict[ID] = {}\n",
    "                X_dict[ID][\"foreground\"] = X_pos_current\n",
    "                X_dict[ID][\"background\"] = X_neg_current\n",
    "    \n",
    "    for idx_ID, ID_group in enumerate(ID_groups):\n",
    "        which_ID_group = idx_ID\n",
    "        save_layer_ID_group_path = os.path.join(save_layer_path, IDs_str[which_ID_group])\n",
    "        if not os.path.exists(save_layer_ID_group_path):\n",
    "            os.mkdir(save_layer_ID_group_path)\n",
    "\n",
    "        flag = True\n",
    "        idx = 0\n",
    "\n",
    "        print(\"\\nFor \"+save_layer_ID_group_path+\"/X_y.npz, the labels: \",end=\"\\n\\n\")\n",
    "        for position_in_group, ID in enumerate(ID_group):\n",
    "            X_pos_current = X_dict[ID]['foreground']\n",
    "            X_neg_current = X_dict[ID]['background']\n",
    "            \n",
    "            print(str(idx)+\" presents concept \"+str(ID)+\" which is \"+str(imagenet_class_parent_and_child_dict[ID]), end=\"\\n\\n\")\n",
    "            if flag:\n",
    "                X = X_pos_current\n",
    "                y = np.ones(X_pos_current.shape[0]) * idx\n",
    "                X_neg = X_neg_current\n",
    "                flag = False\n",
    "                idx+=1\n",
    "            else:\n",
    "                X = np.concatenate((X, X_pos_current))\n",
    "                y = np.concatenate((y, np.ones(X_pos_current.shape[0]) * idx))\n",
    "                X_neg = np.concatenate((X_neg, X_neg_current))\n",
    "                idx+=1\n",
    "        \n",
    "        print(str(idx)+\" presents background info\")\n",
    "        X_neg = X_neg[np.random.randint(X_neg.shape[0], size=int(X.shape[0]/len(ID_group))),:]\n",
    "        X = np.concatenate((X, X_neg))\n",
    "        y = np.concatenate((y, np.ones(X_neg.shape[0]) * (idx)))\n",
    "        \n",
    "        np.savez_compressed(save_layer_ID_group_path+\"/X_y.npz\", X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept classifier and Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_layer = str(layers[0])\n",
    "print(\"chosen layer: \"+chosen_layer)\n",
    "\n",
    "chosen_ID_group = str(ID_groups[0])\n",
    "print(\"chosen_ID_group: \"+chosen_ID_group)\n",
    "\n",
    "X_y = np.load(os.path.join(responisble_regions_save_path, chosen_layer, chosen_ID_group, \"X_y.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_obj_loc = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = copy.deepcopy(X_y[\"y\"])\n",
    "print(\"target is \"+str(chosen_ID_group.split(\",\")[target_obj_loc])+\" | \"+imagenet_class_parent_and_child_dict[int(chosen_ID_group.split(\",\")[target_obj_loc])]['words'])\n",
    "print(\"we will train a concept classifier to distinguish the target from the others in \"+str(chosen_ID_group))\n",
    "y[y!=target_obj_loc] = -1\n",
    "y[y==target_obj_loc] = 1\n",
    "y[y!=1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the concept classifier\n",
    "coef, clf, Validation_score = get_linear_classifier(X_y[\"X\"], y, classifier = \"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = get_xgb_classifier(X_y[\"X\"],y)\n",
    "bst.set_param({\"predictor\": \"gpu_predictor\"})\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(X_y[\"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_arr_mean = []\n",
    "importance_arr_median = []\n",
    "importance_arr_max = []\n",
    "importance_arr_min = []\n",
    "\n",
    "for i in range(shap_values.shape[1]):\n",
    "    shap_vals_of_one_channel = np.abs(shap_values[:,i]) #xgb_shap_values[:,i]\n",
    "    importance_arr_mean.append(np.mean(shap_vals_of_one_channel))\n",
    "    importance_arr_median.append(np.median(shap_vals_of_one_channel))\n",
    "    importance_arr_max.append(np.max(shap_vals_of_one_channel))\n",
    "    importance_arr_min.append(np.min(shap_vals_of_one_channel))\n",
    "\n",
    "importance_arr_mean = np.array(importance_arr_mean)\n",
    "importance_arr_median = np.array(importance_arr_median)\n",
    "importance_arr_max = np.array(importance_arr_max)\n",
    "importance_arr_min = np.array(importance_arr_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot shap vals\n",
    "\n",
    "sort_locs = np.argsort(importance_arr_mean)[::-1]\n",
    "\n",
    "sort_locs_str = []\n",
    "for i in sort_locs:\n",
    "     sort_locs_str.append(str(i))\n",
    "\n",
    "N_subplot = 7\n",
    "len_of_one_sub = int(len(sort_locs)/N_subplot+1)\n",
    "sort_locs_sub = []\n",
    "sort_locs_str_sub = []\n",
    "for i in range(N_subplot):\n",
    "    start_loc = np.clip(i*len_of_one_sub,0,len(sort_locs))\n",
    "    end_loc = np.clip((i+1)*len_of_one_sub,0,len(sort_locs))\n",
    "    sort_locs_sub.append(sort_locs[start_loc:end_loc])\n",
    "    sort_locs_str_sub.append(sort_locs_str[start_loc:end_loc])\n",
    "    \n",
    "fig, axs = plt.subplots(1,N_subplot,figsize=(20,20))\n",
    "\n",
    "for i in range(N_subplot):\n",
    "    axs[i].barh(sort_locs_str_sub[i][::-1],importance_arr_mean[sort_locs_sub[i]][::-1])\n",
    "    axs[i].set_xlim(0, np.max(importance_arr_mean)+0.05)\n",
    "    axs[i].set_xlabel('Shapley')\n",
    "# plt.savefig(\"shap_bar_plot.svg\",\n",
    "#             bbox_inches='tight', dpi=100, pad_inches=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the results of concept classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_for_show = 1095\n",
    "\n",
    "print(ID_for_show, imagenet_class_parent_and_child_dict[ID_for_show]['words'])\n",
    "\n",
    "resized_img_for_show_cat, feature_map_for_show_cat, saliency_map_for_show_cat = \\\n",
    "load_feature_saliency_map_and_resized_img_for_show(feature_maps_and_saliency_maps_path+\"/result_of_ID_\"+str(ID_for_show), chosen_layer)\n",
    "\n",
    "resized_img_for_show_cat = np.array(resized_img_for_show_cat, dtype=int)\n",
    "\n",
    "grayscale_saliency_map = process_cat_saliency_map(saliency_map_for_show_cat, num_of_pic_of_a_row = 10, mode=\"norm\")\n",
    "\n",
    "concept_map = prediction(clf, feature_map_for_show_cat, is_predict_proba = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_concept_region_on_img(resized_img_for_show_cat, concept_map[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
